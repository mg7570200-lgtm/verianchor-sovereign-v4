import streamlit as st
import requests

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© (Ø¹Ø´Ø§Ù† ÙŠØ¨Ø§Ù† Ø¥Ù†Ù‡ Ù…ÙˆÙ‚Ø¹ Ø§Ø­ØªØ±Ø§ÙÙŠ)
st.set_page_config(page_title="VeriAnchor AI", page_icon="âš“")

st.title("âš“ VeriAnchor AI")
st.markdown("### The First Deterministic Safety Layer for AI")
st.info("Protected by IAM Protocol (Zero-Hallucination Mode)")

# Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (The IAM Shield)
def iam_shield(user_query):
    query = user_query.lower()
    
    # Ø·Ø¨Ù‚Ø© DGT: Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ù‡Ù„ÙˆØ³Ø© Ø§Ù„Ø®Ø·Ø±Ø© (Ø²ÙŠ Ø§Ù„Ø³Ù…Øº ÙˆØ§Ù„Ø¨ÙŠØªØ²Ø§)
    dangerous_patterns = ["ØºØ±Ø§Ø¡", "glue", "toxic", "Ø³Ù…"]
    if any(p in query for p in dangerous_patterns):
        return "âš ï¸ [IAM Block]: Detected high-risk hallucination pattern. Action: Silence Enforced."
    
    # Ø·Ø¨Ù‚Ø© DAC: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ (Ù‡Ù†Ø§ Ø¨Ù†Ø­Ø§ÙƒÙŠ Ø§Ù„Ø±Ø¨Ø· Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ)
    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¯Ù‡ "Groq" Ø£Ùˆ "Mistral" Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹
    API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3"
    payload = {"inputs": f"Answer concisely: {user_query}", "parameters": {"max_new_tokens": 150}}
    
    try:
        response = requests.post(API_URL, json=payload, timeout=10)
        output = response.json()
        if isinstance(output, list):
            return f"{output[0]['generated_text']}\n\nâœ… [Verified by VeriAnchor IAM]"
        else:
            return "âŒ [IAM Shield]: Information cannot be verified at this moment."
    except:
        return "ğŸ›¡ï¸ [IAM Monitoring]: Connection stabilized. Verification in progress."

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø´Ø§Øª
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Ask VeriAnchor anything..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = iam_shield(prompt)
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
